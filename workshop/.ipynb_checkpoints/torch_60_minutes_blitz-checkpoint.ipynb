{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.6573e+36]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uninitialized\n",
    "torch.empty(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7148, 0.0289, 0.4189],\n",
       "        [0.3223, 0.6405, 0.8271],\n",
       "        [0.5467, 0.6468, 0.2061],\n",
       "        [0.9913, 0.2140, 0.1812],\n",
       "        [0.0392, 0.9157, 0.1558]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialized\n",
    "torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With type\n",
    "torch.zeros(5, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From data\n",
    "torch.tensor([5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5406,  1.5145, -0.3542],\n",
       "        [ 0.8924,  0.3300, -1.1371],\n",
       "        [-2.4557, -0.2414, -2.3109],\n",
       "        [ 1.3068,  1.0592,  0.4216],\n",
       "        [-0.9412, -1.1299,  1.9326]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From existing tensor\n",
    "x = torch.ones(5, 3, dtype=torch.double)\n",
    "torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2134, 1.2085, 1.0990],\n",
      "        [1.4780, 1.1750, 1.0276],\n",
      "        [1.9295, 0.5874, 1.0015],\n",
      "        [1.5933, 1.5785, 1.4470],\n",
      "        [1.2730, 0.4871, 1.0462]])\n",
      "tensor([[1.2134, 1.2085, 1.0990],\n",
      "        [1.4780, 1.1750, 1.0276],\n",
      "        [1.9295, 0.5874, 1.0015],\n",
      "        [1.5933, 1.5785, 1.4470],\n",
      "        [1.2730, 0.4871, 1.0462]])\n",
      "tensor([[1.2134, 1.2085, 1.0990],\n",
      "        [1.4780, 1.1750, 1.0276],\n",
      "        [1.9295, 0.5874, 1.0015],\n",
      "        [1.5933, 1.5785, 1.4470],\n",
      "        [1.2730, 0.4871, 1.0462]])\n",
      "tensor([[1.2134, 1.2085, 1.0990],\n",
      "        [1.4780, 1.1750, 1.0276],\n",
      "        [1.9295, 0.5874, 1.0015],\n",
      "        [1.5933, 1.5785, 1.4470],\n",
      "        [1.2730, 0.4871, 1.0462]])\n",
      "tensor([[1.2134, 1.2085, 1.0990],\n",
      "        [1.4780, 1.1750, 1.0276],\n",
      "        [1.9295, 0.5874, 1.0015],\n",
      "        [1.5933, 1.5785, 1.4470],\n",
      "        [1.2730, 0.4871, 1.0462]])\n"
     ]
    }
   ],
   "source": [
    "# Different faces of add\n",
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "z = x + y\n",
    "print(z)\n",
    "z = torch.add(x, y)\n",
    "print(z)\n",
    "print(z)\n",
    "torch.add(x, y, out=z)\n",
    "print(z)\n",
    "z = x\n",
    "z.add_(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0990, 1.0276, 1.0015, 1.4470, 1.0462])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing slicing\n",
    "x[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Change shape\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scala value\n",
    "x = torch.tensor(2)\n",
    "print(x)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "[[5. 5. 5.]\n",
      " [5. 5. 5.]]\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Shared memory location with numpy\n",
    "a = torch.ones(2, 3)\n",
    "b = a.numpy()\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a = np.zeros((2, 3))\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 5, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], grad_fn=<PowBackward0>)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<MulBackward0>)\n",
      "tensor(3., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Open the auto_grad\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "# When performing calculation, it create a grad_fn\n",
    "y = x**2\n",
    "print(y)\n",
    "\n",
    "# Performing more calculation\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "tensor(207.3658, grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x1224fcf60>\n"
     ]
    }
   ],
   "source": [
    "# Change required grad in place\n",
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36., 36.],\n",
       "        [36., 36.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform backprop\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x**2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "out.backward(z)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.1920e+02, 8.1920e+03, 8.1920e-01])\n"
     ]
    }
   ],
   "source": [
    "# Example with vector-Jacobian product\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Temporarily turn autograd off\n",
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # init the origin?\n",
    "        super(Net, self).__init__()\n",
    "        # conv layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # fc layers\n",
    "        self.fc1 = nn.Linear(16*6*6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # Flaten\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([120, 576])\n"
     ]
    }
   ],
   "source": [
    "# Show parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "# Show first layers\n",
    "print(params[4].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1061, -0.0452,  0.0014, -0.0356, -0.0383,  0.0768, -0.0819, -0.0427,\n",
      "         -0.0440,  0.0351]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Forward prop\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "# call the forward\n",
    "out = net(input) \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7949, grad_fn=<MseLossBackward>)\n",
      "<MseLossBackward object at 0x123021390>\n",
      "<AddmmBackward object at 0x123056a90>\n",
      "<AccumulateGrad object at 0x123021390>\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([-0.0022,  0.0034,  0.0003,  0.0023, -0.0023,  0.0045])\n"
     ]
    }
   ],
   "source": [
    "# Backprop with loss function\n",
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])\n",
    "\n",
    "net.zero_grad()\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting weights manually\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting weights using optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
